---
tags:
  - 统计学习
  - 非线性模型
  - 核心概念
aliases:
  - Moving Beyond Linearity
  - 非线性回归
  - 基函数
---

# 非线性模型概论 (Moving Beyond Linearity)

## 1. 核心思想
> "The truth is never linear." (真相从未线性) — Trevor Hastie

线性模型 $Y = \beta_0 + \beta_1 X + \epsilon$ 虽然解释性强，但在现实中往往面临**拟合不足 (Underfitting)** 的问题。本章的核心目标是：**放松线性假设，但尽可能保留线性模型的可加性和可解释性**。

## 2. 技术路线图
我们将通过“基函数展开”的方法，将单一变量 $X$ 替换为多个变换函数的组合：
$$y_i = \beta_0 + \beta_1 b_1(x_i) + \beta_2 b_2(x_i) + \dots + \beta_K b_K(x_i) + \epsilon_i$$

| 方法                                                         | 核心逻辑         | 适用场景                  | 编程手直觉                                              |
| :--------------------------------------------------------- | :----------- | :-------------------- | :------------------------------------------------- |
| **[[多项式回归与阶梯函数#1. 多项式回归 (Polynomial Regression)\|多项式回归]]** | 全局 $X^d$ 变换  | 简单的曲线趋势               | `np.polyfit` 或 `PolynomialFeatures`                |
| **[[多项式回归与阶梯函数#2. 阶梯函数 (Step Functions)\|阶梯函数]]**          | 分段常数 (离散化)   | 具有明显阶段性的数据（如年龄段）      | `pd.cut` 分箱 (Binning)                              |
| **[[回归样条]]**                                               | 分段多项式 + 平滑约束 | **MCM 首选**。灵活性与稳定性的平衡 | `patsy` 的 `bs()` 或 `sklearn` 的 `SplineTransformer` |
| **[[平滑样条]]**                                               | 拟合程度 + 惩罚项   | 追求极致平滑，数学性质优美         | 类似 Ridge 的正则化思路                                    |
| **[[局部回归]]**                                               | 滑动窗口加权       | 仅关注局部邻域               | KNN 的回归版 (LOESS)                                   |
| **[[广义加性模型GAM]]**                                          | 多个非线性函数的叠加   | 多变量非线性建模的终极框架         | `pygam` 库                                          |

## 3. 与线性模型的联系
这些方法在技术上仍属于**线性回归框架**（Linear Regression Framework）。
* **为什么？** 因为模型对于**系数** $\beta$ 依然是线性的。
* **好处**：我们之前学的假设检验、置信区间、F检验、交叉验证等工具，**全部可以直接复用**。

## 4. 关联笔记
* ⬅️ 前置知识：[[简单线性回归]], [[多元线性回归]]
* ➡️ 进阶应用：[[广义加性模型GAM]]