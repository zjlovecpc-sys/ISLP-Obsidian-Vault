---
tags:
  - 统计学习
  - 线性回归
  - 核心算法
aliases:
  - Simple Linear Regression
  - 最小二乘法
  - RSS
---

# 简单线性回归

## 核心定义
**简单线性回归** 是一种通过单一预测变量 $X$ 来预测定量响应变量 $Y$ 的方法。我们假设 $X$ 和 $Y$ 之间存在线性关系：
$$Y \approx \beta_0 + \beta_1 X$$

其中 $\beta_0$ 是**截距**，$\beta_1$ 是**斜率**（即 $X$ 每增加1个单位，$Y$ 平均增加的数量）。

## 总体回归线 vs 最小二乘线
- **总体回归线 (Population Regression Line)**：$Y = \beta_0 + \beta_1 X + \epsilon$。这是变量间“真实”的关系，其中 $\epsilon$ 是均值为0的随机误差项。
- **最小二乘线**：这是我们根据数据估算出来的线 $\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x$。

## 参数估计：最小二乘法 (Least Squares)
我们无法知道真实的 $\beta$，只能通过训练数据去估计它们。最常用的方法是**最小二乘法**。

目标是最小化**残差平方和 (RSS)**：
$$\text{RSS} = \sum_{i=1}^n (y_i - \hat{y}_i)^2 = \sum_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2$$

通过微积分求导，我们可以得到 $\hat{\beta}_0$ 和 $\hat{\beta}_1$ 的闭式解（Closed-form solution）。

## 关联笔记
- 如何判断系数算得准不准？见 [[模型参数估计与检验]]。
- 如何判断模型整体好不好？见 [[回归模型评估指标]]。

## 代码实现
- Python 代码模板：[[线性回归_statsmodels实现#1. 简单线性回归]]
- 如何手动验证结果？参考 [[线性回归_statsmodels实现#1. 构建设计矩阵 (Design Matrix)]]