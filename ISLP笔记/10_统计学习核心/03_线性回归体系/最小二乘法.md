---
tags:
  - 统计学习
  - 数学原理
  - 优化算法
aliases:
  - Least Squares
  - RSS
---

# 最小二乘法 (Least Squares)

## 核心定义
最小二乘法是线性回归中用于估计参数 $\beta$ 的标准方法。
它的目标非常直观：**寻找一条直线，使得所有数据点到这条直线的“垂直距离平方和”最小。**

## 核心公式
我们需要最小化 **残差平方和 (RSS)**：
$$RSS = \sum_{i=1}^n (y_i - \hat{y}_i)^2 = \sum_{i=1}^n (y_i - \beta_0 - \beta_1 x_i)^2$$

通过微积分求导，可以得到 $\hat{\beta}_0$ 和 $\hat{\beta}_1$ 的闭式解（Closed-form solution）。

## 关联笔记
- 详细推导见：[[简单线性回归#参数估计：最小二乘法 (Least Squares)]]
- 与极大似然估计的区别：在正态分布假设下，最小二乘法等价于 [[极大似然估计MLE]]。