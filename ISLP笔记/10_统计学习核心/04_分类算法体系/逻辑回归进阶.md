---
tags:
  - 统计学习
  - 逻辑回归
  - 多分类
  - 数据不平衡
aliases:
  - Softmax
  - Case-Control Sampling
  - 多项式逻辑回归
---

# 逻辑回归进阶

## 1. 多分类逻辑回归 (Multinomial Logistic Regression)
当响应变量 $Y$ 有 $K > 2$ 个类别时（如：梨、苹果、橘子），简单的[[逻辑回归]]不再适用。我们使用 **Softmax 函数** 进行推广。

$$P(Y=k|X) = \frac{e^{\beta_{k0} + \beta_{k1}X}}{\sum_{l=1}^K e^{\beta_{l0} + \beta_{l1}X}}$$

- **特点**：所有类别的概率之和为 1。
- **参数**：每个类别都有自己的一组系数 $\beta_k$。

## 2. 罕见事件与病例对照抽样 (Case-Control Sampling)
在医学或欺诈检测中，正样本（如“患病”）往往极其稀有（例如 0.001%）。如果直接采集数据，我们需要数百万个样本才能找到几个病人。

**解决方案**：
1.  **抽样**：收集所有病例 (Cases)，然后按 1:5 的比例随机抽取健康人 (Controls)。这样数据就变成了不平衡的“有偏数据”。
2.  **建模**：直接在有偏数据上跑逻辑回归。
3.  **修正**：
    - **斜率 $\beta_1$**：惊人的结论是，**斜率估计是无偏的**，不需要修正！
    - **截距 $\beta_0$**：截距是错误的，需要根据真实的先验概率 $\pi$ 进行简单的修正：
    $$\hat{\beta}_0^* = \hat{\beta}_0 + \log\frac{\pi}{1-\pi} - \log\frac{\tilde{\pi}}{1-\tilde{\pi}}$$
    (其中 $\pi$ 是真实患病率，$\tilde{\pi}$ 是样本中的患病比例)。

## 关联笔记
- 这是逻辑回归在工业界最常用的两个变体。
- 如果类别之间分得太开，逻辑回归会不稳定，此时应转用 [[判别分析基础|判别分析]]。