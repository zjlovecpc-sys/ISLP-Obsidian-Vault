---
tags:
  - 统计学习
  - LDA
  - 分类算法
  - 生成模型
aliases:
  - Linear Discriminant Analysis
  - 线性判别边界
---

# 线性判别分析 (LDA)

## 核心假设
**LDA (Linear Discriminant Analysis)** 是[[判别分析基础]]的一种特例。为了计算贝叶斯公式中的 $f_k(x)$，它做了两个强假设：
1.  **正态分布**：假设每一类的数据 $X$ 都服从高斯分布 $N(\mu_k, \sigma_k^2)$。
2.  **方差相同**：假设所有类别的方差都相等，即 $\sigma_1^2 = \dots = \sigma_K^2 = \sigma^2$。

## 判别函数 (Discriminant Function)
经过数学推导（对数变换消去 $e$），我们将复杂的概率计算简化为比较**线性分数** $\delta_k(x)$ 的大小：

$$\delta_k(x) = x \cdot \frac{\mu_k}{\sigma^2} - \frac{\mu_k^2}{2\sigma^2} + \log(\pi_k)$$

- **决策规则**：给定一个 $x$，算出所有类别的分数 $\delta_k(x)$，**谁分数高就归谁**。
- **为什么叫“线性”？**：注意公式中 $x$ 是**一次方**。因为假设了方差相同，正态分布公式里的二次项 $x^2$ 在比较时互相抵消了。

## 美赛应用
- 如果你发现数据的协方差矩阵在不同类别间差异巨大（方差不同），LDA 的“方差相同”假设就不成立了，此时应该使用 **二次判别分析 (QDA)**（下一节内容）。

## 代码实现
- Python 核心代码：[[逻辑回归与判别分析实现#3. 判别分析 (Sklearn)]]
- 混淆矩阵绘制：[[逻辑回归与判别分析实现#5. 混淆矩阵 (Confusion Matrix)]]