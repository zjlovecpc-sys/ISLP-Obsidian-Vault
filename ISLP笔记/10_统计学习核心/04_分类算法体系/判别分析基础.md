---
tags:
  - 统计学习
  - 生成模型
  - 贝叶斯定理
aliases:
  - Discriminant Analysis
  - Bayes Theorem
  - 先验概率
---

# 判别分析基础

## 为什么要用判别分析？
既然[[逻辑回归]]那么好用，为什么还要学 LDA？主要有三个理由（见视频 4.5）：
1.  **分离问题**：当类与类之间**分得太开**（Well-separated）时，逻辑回归的参数估计会极其不稳定（趋向于无穷大），而 LDA 很稳。
2.  **小样本稳定性**：当 $n$ 很小且 $X$ 近似正态分布时，LDA 比逻辑回归更准。
3.  **多分类视角**：当 $K > 2$ 时，LDA 提供了低维投影视图，方便可视化。

## 核心思想：贝叶斯定理
[[逻辑回归]]是直接计算 $P(Y|X)$（判别模型）。
**判别分析** 则是先通过数据去模拟每一类的**分布** $f_k(x) = P(X|Y=k)$（生成模型），然后利用**贝叶斯定理**反推归属概率：

$$P(Y=k|X=x) = \frac{\pi_k f_k(x)}{\sum_{l=1}^K \pi_l f_l(x)}$$

### 关键术语
- **先验概率 (Prior, $\pi_k$)**：不看任何数据 $X$，随机抽一个人属于第 $k$ 类的概率。
- **密度函数 (Density, $f_k(x)$)**：第 $k$ 类人群中，$X$ 的分布情况（通常假设为[[线性判别分析LDA|正态分布]]）。
- **后验概率 (Posterior)**：看了数据 $X$ 之后，我们算出的属于第 $k$ 类的概率。

## 关联笔记
- 最常用的具体实现是 [[线性判别分析LDA]]。