---
tags:
  - 统计学习
  - 模型选择
  - LDA
  - 逻辑回归
  - 备赛资料
aliases:
  - Classifier Comparison
  - Model Selection
  - LDA vs Logistic
---

# 分类模型选择指南

在美赛中，面对一个分类问题，该选哪个模型？以下是基于 ISLP 理论及实战经验的深度对比。

## 1. 巅峰对决：LDA vs 逻辑回归
这是最常纠结的一对。根据实验经验，我们有以下**四大判据**：

| 场景 | 推荐模型 | 核心原因 (理论支撑) |
| :--- | :--- | :--- |
| **A. 类别分得特别开**<br>(Well-Separated Classes) | **LDA** | **参数稳定性**。如果“红豆”和“绿豆”离得太远，逻辑回归的参数 $\hat{\beta}$ 会趋向于无穷大，导致模型极其不稳定（无法收敛）。而 LDA 依然稳健。 |
| **B. 样本量很小**<br>(Small Sample Size) | **LDA** | **方差控制**。LDA 预设了强假设（正态分布、同方差），这相当于给模型加了“约束”，减少了自由度，因此在小样本下更不容易过拟合（低方差）。 |
| **C. 多分类问题**<br>(Classes > 2) | **LDA** | **原生支持**。虽然逻辑回归有 Softmax 推广，但在 ISLP 语境下，LDA 的投影视角能提供更清晰的低维可视化（如将数据投影到 2D 平面看分布）。 |
| **D. 追求解释性**<br>(Inference & Interpretation) | **逻辑回归** | **统计意义**。逻辑回归的系数 $\beta$ 代表“对数几率”的变化，容易向非专业人士解释：“Lag1 每增加 1 单位，上涨概率增加多少”。而 LDA 的系数是基于方差归一化的，物理意义不直观。 |

## 2. 线性 vs 非线性边界
- **决策边界近似线性**：
    - **[[逻辑回归]] / [[线性判别分析LDA|LDA]]**：首选。
- **决策边界高度非线性**：
    - **[[二次判别分析QDA|QDA]]**：如果样本量 $n$ 足够大，且想要保留一定的解释性。
    - **[[K最近邻法|KNN]]**：如果只想预测准确，不在乎解释性，且 $p$ 不是特别大。

## 3. 偏差-方差权衡谱系
（从左到右：假设越强，偏差 $\uparrow$，方差 $\downarrow$）

| 朴素贝叶斯 | LDA | 逻辑回归 | QDA | KNN |
| :--- | :--- | :--- | :--- | :--- |
| **极强假设**<br>(特征独立) | **强假设**<br>(正态+同方差) | **线性假设**<br>(Logit线性) | **弱假设**<br>(正态+异方差) | **无假设**<br>(非参数) |
| 适合高维 $p \gg n$ | 适合小样本 $n$ 小 | 通用基准 | 适合非线性且 $n$ 大 | 适合复杂边界 |

## 4. 特殊场景
- **需要概率输出**：首选 **逻辑回归** 或 **LDA/QDA**。KNN 的概率输出通常不够平滑。
- **类别不平衡**：逻辑回归（需调整阈值或采样）或 LDA。
- **特征维度 $p$ 极大**：首选 **[[朴素贝叶斯]]**。
- **解释性要求高**：**逻辑回归**（可以通过 $\beta$ 系数讲故事）。

## 5. 终极策略
在论文中，最佳做法通常是：**先跑逻辑回归作为 Baseline，然后尝试 LDA/QDA/KNN，利用 [[混淆矩阵与ROC|CV/AUC]] 对比效果，选择最好的那个。** 这种“模型筛选”的过程本身就是论文加分项。

