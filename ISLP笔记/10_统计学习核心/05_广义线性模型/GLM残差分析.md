---
tags:
  - 统计学习
  - 残差分析
  - 模型诊断
aliases:
  - Pearson Residuals
  - 皮尔逊残差
  - IRLS
---

# GLM 残差分析

## 原始残差 vs 皮尔逊残差
在 [[简单线性回归]] 中，我们直接看原始残差 $e_i = y_i - \hat{y}_i$。但在 GLM 中，由于存在异方差性（Heteroscedasticity），原始残差不再适用。

### 1. 原始残差 (Raw Residuals)
$$e_i = y_i - \hat{y}_i$$
- **缺陷**：对于计数或金额数据，方差随均值增大。因此 $\hat{y}$ 越大的点，其 $e_i$ 的自然波动范围也越大。
- **表现**：残差图呈现 **漏斗形 (Funnel Shape)**。这通常不是模型错了，而是数据的物理特性。

### 2. 皮尔逊残差 (Pearson Residuals)
为了诊断模型拟合好坏，我们需要消除方差变化的影响，对残差进行标准化：
$$r_i = \frac{y_i - \hat{y}_i}{\sqrt{Var(\hat{y}_i)}}$$
- **分母**：模型假设的方差（例如泊松分布中分母为 $\sqrt{\hat{y}}$）。
- **理想状态**：如果模型选对了（即假设方差 $\approx$ 真实方差），皮尔逊残差图应该呈现**均匀的矩形带**，无明显趋势。

## 方差如何影响模型拟合？
虽然残差公式看似简单，但方差假设通过 **加权最小二乘 (Iteratively Reweighted Least Squares, IRLS)** 算法影响参数估计：

### 权重机制
模型在拟合时，会给每个样本点分配权重 $W_i$：
$$W_i \propto \frac{1}{Var(Y_i)}$$
- **方差小的点**（更可靠）：权重高，模型优先拟合。
- **方差大的点**（波动大）：权重低，模型对其偏差的容忍度高。

这意味着，**方差假设直接决定了回归线 $\hat{y}$ 被哪些数据点“拉过去”**，从而间接决定了残差的大小。

## 关联笔记
- 这是判断是否需要使用 [[负二项回归]] 或 [[Gamma回归]] 的主要依据。
