---
tags:
  - 统计学习
  - 核心理论
  - 必背公式
aliases:
  - Bias-Variance Trade-off
  - 偏差方差分解
---

# 偏差-方差权衡

这是统计学习中最著名、最重要的理论结论之一。

## 核心原理
对于任何给定的测试数据点 $x_0$，其期望测试均方误差 (Expected Test MSE) 可以分解为三部分之和：

$$E(y_0 - \hat{f}(x_0))^2 = \text{Var}(\hat{f}(x_0)) + [\text{Bias}(\hat{f}(x_0))]^2 + \text{Var}(\epsilon)$$

## 三大成分
1.  **方差 (Variance)**：指如果我们用不同的训练数据集重复训练模型，预测函数 $\hat{f}$ 的变化程度。
    * *高方差*意味着模型对训练数据极其敏感（如高阶多项式，[[K最近邻法#K值的选择（关键）|K最近邻法]]中 K=1）。
2.  **偏差 (Bias)**：指模型假设与真实关系之间的固有误差。
    * *高偏差*意味着模型太简单，无法捕捉真实规律（如用直线去拟合曲线，欠拟合）。
3.  **不可约误差 (Irreducible Error, $\text{Var}(\epsilon)$)**：由数据本身的噪声决定，无论模型多好都无法消除。

## 权衡 (The Trade-off)
- 增加模型灵活性 $\rightarrow$ 偏差 $\downarrow$ ，方差 $\uparrow$。
- 减少模型灵活性 $\rightarrow$ 偏差 $\uparrow$ ，方差 $\downarrow$。
- **目标**：找到偏差和方差之和最小的那个“甜蜜点” (Sweet Spot)。这也是我们在美赛中调节超参数（如 [[K最近邻法]] 的 K 值）的理论依据。