---
tags:
  - 统计学习
  - 重采样
  - Bootstrap
  - 参数估计
aliases:
  - Bootstrapping
  - 置信区间
  - 标准误估计
---

# 自助法 (The Bootstrap)

## 核心定义
**自助法 (Bootstrap)** 是一种极其强大且通用的统计工具。它的核心用途不是为了“训练模型”，而是为了**衡量估计量的不确定性**（如计算标准误、置信区间）。

_学术表述_：Bootstrap 的本质是用观测到的数据的**经验分布** $\hat{F}$ 来代替未知的**总体分布** $F$，并从 $\hat{F}$ 中进行重采样。这被称为 **“插件原理” (Plug-in Principle)**。

* **名字由来**：源自谚语 "To pull oneself up by one's bootstraps"（提着靴子上的带子把自己提起来），寓意在没有额外数据的情况下，仅靠现有的样本“自己帮自己”。

## 为什么需要它？
在 [[简单线性回归]] 中，我们有现成的数学公式来计算 $\hat{\beta}$ 的标准误 $SE(\hat{\beta})$。
但在现实美赛中，我们经常遇到复杂的统计量（如中位数、分位数、两组数据的比值），这些统计量**没有简单的标准误公式**。

此时，Bootstrap 允许我们要利用计算机的算力，通过模拟采样来暴力求解标准误。

## 算法流程
假设我们有原始数据集 $Z$（包含 $n$ 个观测点）。我们想估计某个统计量 $\alpha$ 的标准误。

1.  **有放回抽样 (Sampling with Replacement)**：
    从原始数据集 $Z$ 中随机抽取 $n$ 个观测值，组成第一个自助数据集 $Z^{*1}$。
    * *关键*：因为是“有放回”，同一个样本点可能在 $Z^{*1}$ 中出现多次，也可能一次都不出现。

2.  **重复计算**：
    重复上述过程 $B$ 次（通常 $B=1000$ 或更多），得到 $B$ 个自助数据集 $Z^{*1}, Z^{*2}, \dots, Z^{*B}$。

3.  **参数估计**：
    在每个自助数据集上计算我们关心的统计量，得到 $B$ 个估计值 $\hat{\alpha}^{*1}, \hat{\alpha}^{*2}, \dots, \hat{\alpha}^{*B}$。

4.  **计算标准误**：
    这 $B$ 个估计值的**样本标准差**，就是我们要找的 Bootstrap 标准误：
    $$SE_B(\hat{\alpha}) = \sqrt{\frac{1}{B-1} \sum_{r=1}^B (\hat{\alpha}^{*r} - \bar{\hat{\alpha}}^{*})^2}$$

## 样本覆盖率与袋外 (OOB) 观测
在构建每个 Bootstrap 数据集时，原始数据集中大约有 **1/3** 的样本**不会**被选中。这部分样本被称为 **OOB (Out-of-Bag)** 样本。

* **概率推导**：
    * 对于任意一个特定的样本，它在一次抽样中**未被选中**的概率是 $1 - 1/n$。
    * 经过 $n$ 次独立抽样，它从未被选中的概率是：
      $$\lim_{n \to \infty} (1 - \frac{1}{n})^n = \frac{1}{e} \approx 0.368$$
* **结论**：平均而言，每个 Bootstrap 数据集只包含原始数据中约 **63.2%** 的不同观测值。
* **应用**：在 [[随机森林]] 等算法中，我们不需要专门划分验证集，直接利用这 36.8% 的 OOB 数据来测试模型性能（即 OOB 误差），效果等同于交叉验证。

## 美赛应用场景
* **复杂的非线性参数**：比如你要估计“投资组合风险价值 (VaR)”的置信区间。
* **小样本数据**：数据太少，不敢划分验证集，但又想给出一个“带有误差范围”的预测结果。

实战链接：[[Bootstrap实战#4. 巅峰对决：Bootstrap SE vs. 公式 SE]]