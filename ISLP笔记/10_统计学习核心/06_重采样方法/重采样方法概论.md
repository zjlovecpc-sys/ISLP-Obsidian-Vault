---
tags:
  - 统计学习
  - 重采样
  - 核心概念
aliases:
  - Resampling Methods
  - Model Assessment
  - Model Selection
---

# 重采样方法概论

## 核心定义
**重采样方法 (Resampling Methods)** 是现代统计学中不可或缺的工具。它的核心思想是：通过从原始训练样本中反复抽取样本，并重新拟合感兴趣的模型，来获取关于该拟合模型的更多信息。

这对美赛编程手来说意味着：**用计算力换取统计推断能力**。

## 两大核心任务
在 ISLP 第五章中，重采样主要用于解决两个不同的问题：

1.  **模型评估 (Model Assessment)**：
    * **目的**：评估一个模型的预测性能（泛化能力）。
    * **场景**：我们已经选定了一个模型（如线性回归），想知道它在未知数据上的误差（测试误差）有多大。
    * **工具**：[[验证集方法]]、[[留一法交叉验证]]、[[K折交叉验证]]。

2.  **模型选择 (Model Selection)**：
    * **目的**：在多个模型或不同超参数中选择最好的那个。
    * **场景**：选择 [[K最近邻法]] 中最好的 $K$ 值；选择 [[回归扩展模型#2. 多项式回归 (Polynomial Regression)|多项式回归]] 的阶数。
    * **工具**：同上（通过比较不同模型的 CV 误差）。

3.  **参数精度估计**：
    * **目的**：当没有现成的数学公式可以计算参数的方差或置信区间时（例如计算中位数的标准误）。
    * **工具**：[[自助法]] (Bootstrap)。

## 关联笔记
- 为什么不直接看训练误差？请回顾 [[均方误差MSE#关键结论|训练MSE vs 测试MSE]]。