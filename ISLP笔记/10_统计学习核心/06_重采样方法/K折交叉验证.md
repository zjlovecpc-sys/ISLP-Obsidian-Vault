---
tags:
  - 统计学习
  - 重采样
  - 交叉验证
  - 黄金标准
aliases:
  - K-Fold Cross-Validation
  - 5折交叉验证
  - 10折交叉验证
---

# K折交叉验证 (K-Fold CV)

## 核心原理
为了平衡 [[验证集方法]]（方差大、偏差高）和 [[留一法交叉验证]]（计算慢、方差高）的缺陷，我们提出了 **K折交叉验证**。

1.  将数据随机分成大小相似的 **$K$** 个组（Folds）。
2.  **循环 $K$ 次**：
    * 第 $k$ 组作为**验证集**。
    * 其余 $K-1$ 组作为**训练集**。
    * 计算 MSE。
3.  取平均值作为最终评估结果。

$$CV_{(K)} = \frac{1}{K} \sum_{k=1}^K MSE_k$$

## K 选多少？
在美赛和工业界，最常用的选择是：
* **$K=5$** 或 **$K=10$**。
* 这也是 `sklearn` 中 `cross_val_score` 的默认习惯。

## 偏差-方差权衡 (LOOCV vs K-Fold)
这是 Chapter 5 最深刻的理论点：

| 方法 | 偏差 (Bias) | 方差 (Variance) | 解释 |
| :--- | :--- | :--- | :--- |
| **验证集方法** | 高 | 高 | 数据用得少（偏差高）；随机切分依赖运气（方差高）。 |
| **LOOCV ($K=n$)** | **极低** | **高** | 模型之间**高度正相关**。平均很多高度相关的量，并不能有效降低方差。 |
| **K-Fold ($K=10$)** | 低 | **低** | 训练集重叠较少，模型相关性低。偏差与方差的最佳折中点 (Sweet Spot)。 |

### 深度解析：为什么 LOOCV 方差反而高？

这个结论反直觉，因为我们通常认为“数据越多，方差越小”。但在交叉验证中，我们是在**对“误差评估结果”的稳定性**进行讨论。

1.  **直觉理解（模型相关性）**：
    * **LOOCV 的模型是“克隆人”**：每次训练只换掉 1 个样本。这意味着 $n$ 个模型几乎一模一样。如果原始数据中有一个怪异的噪声点，这 $n$ 个模型大概率都会受影响。它们的误差是“同进退”的（高度正相关）。
    * **K-Fold 的模型是“表兄弟”**：每次训练换掉 $1/K$ 的数据（比如 10%）。模型之间的差异更大，相关性更低。

2.  **统计学解释**：
    * 假设我们要计算平均值 $\bar{X} = \frac{1}{m} \sum X_i$。
    * 统计学公式告诉我们：$\text{Var}(\bar{X})$ 不仅取决于单个 $X_i$ 的方差，还取决于它们之间的**相关系数 (Correlation, $\rho$)**。
        $$\text{Var}(\text{Mean}) \approx \frac{\sigma^2}{m} + \rho \cdot \sigma^2$$
    * **LOOCV**：$\rho \approx 1$（极高）。即使 $m=n$ 很大，后面那一项 $\rho \cdot \sigma^2$ 依然很大，导致总方差降不下来。
    * **K-Fold**：$\rho$ 较小。平均后的结果更稳定。

3.  **比喻**：
    * **LOOCV**：像问 100 个读了**同一本教材**的学生。如果教材有一处印错了，大家全错。平均分波动很大（取决于那本教材）。
    * **K-Fold**：像问 10 个读了**不同版本教材**的学生。错误被分散了，平均分更能反映真实水平。

## 分类问题中的 CV
对于分类问题（如 [[逻辑回归]]），原理完全一样，只是把 MSE 换成 **错误率 (Error Rate)**：
$$CV_K = \frac{1}{K} \sum_{k=1}^K Err_k$$
其中 $Err_k$ 是第 $k$ 折验证集上的误分类比例。

## 致命陷阱：特征选择与 CV 的顺序
在美赛中，这是最容易导致**结果虚高（作弊）**的错误。

### ❌ 错误的做法
1.  先利用**所有样本**计算特征与 $Y$ 的相关性，选出前 100 个强特征。
2.  **然后**再进行 K折交叉验证，评估模型性能。
* **后果**：严重低估误差。因为你在步骤 1 中已经让模型“偷看”了全卷答案。这叫 **数据泄露 (Data Leakage)**。

### ✅ 正确的做法
1.  将数据分为 $K$ 折。
2.  **在每一折的训练集内**，独立进行特征选择（选出前 100 个）。
3.  用选出的特征训练模型，并在**验证集**上测试。
* **关键**：特征选择也是模型训练的一部分，必须被包含在 CV 循环内部！

实战链接：[[交叉验证实战#3. K折交叉验证 (K-Fold CV)]]