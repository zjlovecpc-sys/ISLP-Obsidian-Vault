---
tags:
  - 统计学习
  - 高维数据
  - 维度灾难
aliases:
  - High-Dimensional Data
  - Curse of Dimensionality
  - p > n
---

# 高维数据问题 (High-Dimensional Data)

## 核心定义
传统统计学通常假设 $n \gg p$（样本量远大于变量数）。
但在现代美赛题目（如基因数据、图像数据）中，常出现 **$p > n$** 的情况，即预测变量的数量超过了样本量。这被称为 **高维数据**。

## 最小二乘法的崩溃
当 $p \ge n$ 时，标准线性回归 ([[最小二乘法]]) 会彻底失效：
1.  **多重解**：方程组包含的未知数多于方程数，存在无穷多组系数解能使训练误差 $RSS = 0$。
2.  **过拟合**：模型会完美拟合训练数据（穿过每一个点），但在测试集上表现极差。
3.  **计算失效**：设计矩阵 $X^TX$ 不可逆，无法求解标准方程。

## 应对策略
在 $p > n$ 的高维场景下，我们**必须**放弃无偏估计，引入偏差来降低方差：
1.  **正则化**：使用 [[岭回归]] 或 [[套索回归]]。即便 $p > n$，加上惩罚项后解依然唯一。
2.  **降维**：使用 [[降维方法]] (PCR) 将变量压缩到 $M < n$ 个主成分。
3.  **稀疏性假设**：假设在高维空间中，只有少数几个变量真正起作用。此时 [[套索回归]] 是最佳选择。

## 维度灾难 (Curse of Dimensionality)
随着维度 $p$ 的增加，数据点在高维空间中变得极其**稀疏**。
* **后果**：我们需要呈指数级增长的样本量 $n$ 才能维持相同的预测精度。
* **启示**：在美赛中，永远不要为了“显得高级”而盲目增加特征。每增加一个特征，都要警惕是否引入了过多的噪声。