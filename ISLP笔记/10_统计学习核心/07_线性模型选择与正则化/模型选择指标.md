---
tags:
  - 统计学习
  - 模型评估
  - AIC
  - BIC
aliases:
  - Model Selection Criteria
  - Adjusted R2
  - Cp Statistic
---

# 模型选择指标 (Model Selection Criteria)

## 核心问题
为什么不能直接用 RSS 或 $R^2$ 来选择模型？
* **原因**：RSS 和 $R^2$ 衡量的是**训练误差**。随着变量数量 $d$ 的增加，训练 RSS 必然单调下降，$R^2$ 必然单调上升。
* **后果**：直接使用它们会永远选择包含所有变量的复杂模型，导致严重**过拟合**。
* **解决方案**：需要对训练误差进行**惩罚 (Penalty)**，以抵消模型复杂度带来的偏差。

## 1. $C_p$ 统计量
对于含有 $d$ 个预测变量的最小二乘模型：
$$C_p = \frac{1}{n} (RSS + 2d\hat{\sigma}^2)$$
* $\hat{\sigma}^2$：误差方差 $\epsilon$ 的估计值（通常用全模型的均方误差）。
* **惩罚项**：$2d\hat{\sigma}^2$。模型越复杂（$d$ 越大），惩罚越重。
* **判据**：$C_p$ 值越**小**越好。

## 2. AIC (赤池信息量准则)
源自最大似然估计。在线性回归（误差服从正态分布）中，AIC 与 $C_p$ 成正比：
$$AIC = \frac{1}{n\hat{\sigma}^2} (RSS + 2d\hat{\sigma}^2)$$
* **判据**：AIC 值越**小**越好。

## 3. BIC (贝叶斯信息量准则)
源自贝叶斯观点：
$$BIC = \frac{1}{n} (RSS + \log(n)d\hat{\sigma}^2)$$
* **惩罚项**：$\log(n)d\hat{\sigma}^2$。
* **对比**：因为通常 $n > 7$ (即 $\log n > 2$)，所以 BIC 对复杂模型的惩罚比 $C_p$ **更重**。
* **倾向**：BIC 倾向于选择**更简单**（变量更少）的模型。

## 4. 调整 $R^2$ (Adjusted $R^2$)
对传统 $R^2$ 进行自由度修正：
$$\text{Adjusted } R^2 = 1 - \frac{RSS / (n - d - 1)}{TSS / (n - 1)}$$
* **原理**：当添加一个无关变量时，$RSS$ 会轻微下降，但分母 $n-d-1$ 也会减小。如果 $RSS$ 下降的幅度不够大，整体分数值反而会变大，导致 Adjusted $R^2$ 减小。
* **判据**：值越**大**越好（注意方向与其他指标相反）。

## 美赛实战建议
* **首选**：在现代计算能力下，优先使用 **[[交叉验证实战|交叉验证]]** 直接估计测试误差，因为它依赖的假设最少。
* **备选**：如果计算资源受限，BIC 是筛选稀疏模型（Sparse Model）的好工具。