---
tags:
  - 统计学习
  - 数据预处理
  - 核心技巧
aliases:
  - Standardization
  - Scale Invariant
  - Z-Score
---

# 数据标准化 (Standardization)

## 核心定义
数据标准化是将变量进行缩放，使其具有 **均值为 0** 和 **标准差为 1** 的过程。
公式如下：
$$\tilde{x}_{ij} = \frac{x_{ij} - \bar{x}_j}{\sqrt{\frac{1}{n-1} \sum_{i=1}^n (x_{ij} - \bar{x}_j)^2}}$$

## 为什么这一章必须标准化？
在 [[最小二乘法]] 中，如果我们将某个变量 $X_j$ 乘以常数 $c$，其系数 $\hat{\beta}_j$ 会自动变为 $\hat{\beta}_j / c$，预测结果 $\hat{y}$ 保持不变。这叫 **尺度不变性 (Scale Invariant)**。

但在 **[[岭回归]]** 和 **[[套索回归]]** 中，惩罚项 $\lambda \sum \beta_j^2$ 或 $\lambda \sum |\beta_j|$ 对系数的大小非常敏感：
1.  **不公平惩罚**：如果 $X_j$ 的单位是“毫米”（数值很大），$\beta_j$ 就会很小；如果单位是“千米”（数值很小），$\beta_j$ 就会很大。
2.  **后果**：正则化项会倾向于过度惩罚那些单位较大的变量对应的系数，即使它们很重要。

## 最佳实践
* **铁律**：在使用 Ridge, Lasso, PCR, PLS 之前，**必须**对所有预测变量进行标准化。
* **例外**：截距项 $\beta_0$ 不需要标准化（也不参与惩罚）。
* **实战实现**：在 Python 中使用 `StandardScaler`，且必须遵循 [[交叉验证实战#⚠️ 警示：数据泄露与 Pipeline|Pipeline]] 规范，防止数据泄露。

## 关联笔记
* [[岭回归]]
* [[套索回归]]
* [[主成分分析（待后期完善）]]